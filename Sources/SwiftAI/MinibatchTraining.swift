/*
This file was autogenerated from 03_minibatch_training.ipynb
        
If you edit it, be sure that:
  1. there is no diff between this file and the corresponding notebook prior to editing
  2. you don't touch the comments looking like // cell ## as it would break the way back to the notebook
        
Run *** when you are done to update the notebooks with your change.
*/
        
//cell2
import Path
import TensorFlow

//cell5
public typealias TI = Tensor<Int32>

//cell43
public func accuracy(_ output: TF, _ target: TI) -> TF{
    let corrects = TF(output.argmax(squeezingAxis: 1) .== target)
    return corrects.mean()
}

//cell64
public func batchedRanges(start:Int, end:Int, bs:Int) -> UnfoldSequence<Range<Int>,Int>
{
  return sequence(state: start) { (batchStart) -> Range<Int>? in
    let remaining = end - batchStart
    guard remaining > 0 else { return nil}
    let currentBs = min(bs,remaining)
    let batchEnd = batchStart.advanced(by: currentBs)
    defer {  batchStart = batchEnd  }
    return batchStart ..< batchEnd
  }
}

//cell68
public struct DataBatch<Inputs: Differentiable & TensorGroup, Labels: TensorGroup>: TensorGroup {
    public var xb: Inputs
    public var yb: Labels
    
    public init(xb: Inputs, yb: Labels){ (self.xb,self.yb) = (xb,yb) }
    
    public init<C: RandomAccessCollection>(_handles: C) where C.Element: _AnyTensorHandle {
        let xStart = _handles.startIndex
        let xEnd = _handles.index(
            xStart, offsetBy: Int(Inputs._tensorHandleCount))
        self.xb = Inputs.init(_handles: _handles[xStart..<xEnd])
        self.yb = Labels.init(_handles: _handles[xEnd..<_handles.endIndex])
    }
}

//cell78
@differentiable(wrt: logits)
public func crossEntropy(_ logits: TF, _ labels: TI) -> TF {
    return softmaxCrossEntropy(logits: logits, labels: labels)
}
